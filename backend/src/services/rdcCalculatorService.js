// [advice from AI] RDC í•˜ë“œì›¨ì–´ ê³„ì‚°ê¸° ì„œë¹„ìŠ¤ - Fallback ë¡œì§ í¬í•¨
// ì™¸ë¶€ API ì¥ì•  ì‹œì—ë„ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ì œê³µ

const axios = require('axios');

class RDCCalculatorService {
  constructor() {
    this.baseURL = 'http://rdc.rickyson.com:5001';
    this.timeout = 30000; // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    this.retryAttempts = 3;
    this.retryDelay = 1000; // 1ì´ˆ
  }

  /**
   * [advice from AI] ì§€ì—° í•¨ìˆ˜ - ì¬ì‹œë„ ë¡œì§ìš©
   */
  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * [advice from AI] RDC API í—¬ìŠ¤ì²´í¬
   */
  async checkHealth() {
    try {
      const response = await axios.get(`${this.baseURL}/health`, {
        timeout: 5000
      });
      return response.status === 200;
    } catch (error) {
      console.error('RDC Health check failed:', error.message);
      return false;
    }
  }

  /**
   * [advice from AI] ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ RDC API í˜¸ì¶œ
   */
  async callRDCAPIWithRetry(requirements, gpuType = 'auto') {
    for (let attempt = 1; attempt <= this.retryAttempts; attempt++) {
      try {
        console.log(`RDC API í˜¸ì¶œ ì‹œë„ ${attempt}/${this.retryAttempts}`);
        
        const response = await axios.post(`${this.baseURL}/api/calculate`, {
          requirements,
          gpu_type: gpuType
        }, {
          headers: {
            'Content-Type': 'application/json',
          },
          timeout: this.timeout
        });

        console.log('RDC API í˜¸ì¶œ ì„±ê³µ');
        return {
          success: true,
          data: response.data,
          source: 'rdc_api'
        };
      } catch (error) {
        console.error(`RDC API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ ${attempt}):`, error.message);
        
        if (attempt < this.retryAttempts) {
          await this.delay(this.retryDelay * attempt); // ì§€ìˆ˜ì  ë°±ì˜¤í”„
        }
      }
    }

    console.log('ëª¨ë“  RDC API í˜¸ì¶œ ì‹œë„ ì‹¤íŒ¨, Fallback ë¡œì§ ì‚¬ìš©');
    return null;
  }

  // [advice from AI] ë­ì‚¬ AICC ì†”ë£¨ì…˜ ì „ìš© ê³„ì‚° ë©”ì„œë“œ
  async calculateLangsaAICC(requirements, gpuType = 'auto') {
    try {
      console.log('ğŸ¤– ë­ì‚¬ AICC ì†”ë£¨ì…˜ ê³„ì‚° ì‹œì‘:', requirements);

      // [advice from AI] ë­ì‚¬ AICC ì„œë¹„ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ê³„ìˆ˜
      const langsaCoefficients = {
        // ê³ ê° ëŒ€í™” ì„œë¹„ìŠ¤
        callbot: { cpu: 0.5, memory: 1.0, gpu: 0.1 },      // ì½œë´‡: ìŒì„± ì²˜ë¦¬ë¡œ GPU í•„ìš”
        chatbot: { cpu: 0.3, memory: 0.5, gpu: 0.05 },     // ì±—ë´‡: í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ„ì£¼
        advisor: { cpu: 0.4, memory: 0.8, gpu: 0.08 },     // ì–´ë“œë°”ì´ì €: ë³µí•© AI ì²˜ë¦¬
        
        // AI ì²˜ë¦¬ ì„œë¹„ìŠ¤
        stt: { cpu: 0.8, memory: 1.5, gpu: 0.2 },          // STT: ìŒì„± ì¸ì‹, GPU ì§‘ì•½ì 
        tts: { cpu: 0.6, memory: 1.2, gpu: 0.15 },         // TTS: ìŒì„± í•©ì„±
        ta: { cpu: 1.0, memory: 2.0, gpu: 0.1 },           // TA: í…ìŠ¤íŠ¸ ë¶„ì„
        qa: { cpu: 0.8, memory: 1.5, gpu: 0.05 }           // QA: í’ˆì§ˆ ë¶„ì„
      };

      // [advice from AI] ê¸°ë³¸ ì¸í”„ë¼ ë¦¬ì†ŒìŠ¤
      const baseInfrastructure = {
        cpu: 4,      // ê¸°ë³¸ ì¸í”„ë¼ CPU
        memory: 8,   // ê¸°ë³¸ ì¸í”„ë¼ ë©”ëª¨ë¦¬
        storage: 100 // ê¸°ë³¸ ìŠ¤í† ë¦¬ì§€
      };

      // [advice from AI] ì„œë¹„ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ê³„ì‚°
      let totalCpu = baseInfrastructure.cpu;
      let totalMemory = baseInfrastructure.memory;
      let totalGpu = 0;
      let totalStorage = baseInfrastructure.storage;

      const serviceBreakdown = {};

      Object.entries(requirements).forEach(([service, count]) => {
        if (langsaCoefficients[service] && count > 0) {
          const coeff = langsaCoefficients[service];
          const serviceCpu = Math.ceil(count * coeff.cpu);
          const serviceMemory = Math.ceil(count * coeff.memory);
          const serviceGpu = Math.ceil(count * coeff.gpu);
          
          totalCpu += serviceCpu;
          totalMemory += serviceMemory;
          totalGpu += serviceGpu;
          totalStorage += Math.ceil(count * 10); // ì„œë¹„ìŠ¤ë‹¹ 10GB ìŠ¤í† ë¦¬ì§€

          serviceBreakdown[service] = {
            channels: count,
            cpu: serviceCpu,
            memory: serviceMemory,
            gpu: serviceGpu
          };
        }
      });

      // [advice from AI] ì„œë²„ êµ¬ì„± í…Œì´ë¸” ìƒì„±
      const serverConfigurations = [
        {
          role: 'AI Processing Server',
          cpu_cores: Math.max(8, Math.ceil(totalCpu * 0.6)),
          ram_gb: Math.max(16, Math.ceil(totalMemory * 0.6)),
          quantity: Math.ceil(totalGpu / 4) || 1,
          gpu_type: totalGpu > 0 ? 'T4' : '-',
          gpu_quantity: totalGpu > 0 ? Math.min(4, totalGpu) : 0
        },
        {
          role: 'Application Server',
          cpu_cores: Math.max(4, Math.ceil(totalCpu * 0.3)),
          ram_gb: Math.max(8, Math.ceil(totalMemory * 0.3)),
          quantity: Math.ceil((requirements.callbot + requirements.chatbot + requirements.advisor) / 20) || 1,
          gpu_type: '-',
          gpu_quantity: 0
        },
        {
          role: 'Database Server',
          cpu_cores: Math.max(4, Math.ceil(totalCpu * 0.1)),
          ram_gb: Math.max(8, Math.ceil(totalMemory * 0.1)),
          quantity: 1,
          gpu_type: '-',
          gpu_quantity: 0
        }
      ];

      // [advice from AI] ë¹„ìš© ì¶”ì • (ê°„ì†Œí™”ëœ ê³„ì‚°)
      const estimatedCostAWS = serverConfigurations.reduce((total, server) => {
        let serverCost = 0;
        if (server.gpu_quantity > 0) {
          serverCost = 500; // GPU ì„œë²„ ê¸°ë³¸ ë¹„ìš©
        } else {
          serverCost = server.cpu_cores * 10 + server.ram_gb * 5; // CPU/ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¹„ìš©
        }
        return total + (serverCost * server.quantity);
      }, 0);

      const result = {
        success: true,
        message: 'ë­ì‚¬ AICC ì†”ë£¨ì…˜ í•˜ë“œì›¨ì–´ ê³„ì‚° ì™„ë£Œ',
        solution_type: 'langsa_aicc',
        resources: {
          cpu: {
            total: totalCpu,
            breakdown: serviceBreakdown
          },
          actual_memory_gb: totalMemory,
          gpu: {
            total: totalGpu,
            type: 'T4'
          },
          storage: {
            yearly_tb: totalStorage / 1024
          }
        },
        server_config_table: serverConfigurations,
        aws_cost_analysis: {
          total_monthly_cost_usd: estimatedCostAWS,
          total_annual_cost_usd: estimatedCostAWS * 12,
          instance_breakdown: serverConfigurations.map(server => ({
            server_role: server.role,
            total_monthly_cost: (server.cpu_cores * 10 + server.ram_gb * 5) * server.quantity,
            quantity: server.quantity,
            aws_instance: {
              instance_type: server.gpu_quantity > 0 ? 'g4dn.xlarge' : 'c5.2xlarge',
              vcpu: server.cpu_cores,
              memory_gb: server.ram_gb,
              gpu_count: server.gpu_quantity,
              gpu_type: server.gpu_type !== '-' ? server.gpu_type : undefined
            }
          }))
        },
        ncp_cost_analysis: {
          total_monthly_cost_krw: estimatedCostAWS * 1200, // USD to KRW í™˜ì‚°
          total_annual_cost_krw: estimatedCostAWS * 1200 * 12,
          instance_breakdown: serverConfigurations.map(server => ({
            server_role: server.role,
            total_monthly_cost: (server.cpu_cores * 12000 + server.ram_gb * 6000) * server.quantity,
            quantity: server.quantity,
            ncp_instance: {
              instance_type: server.gpu_quantity > 0 ? 'g1.c8m32.g1' : 'c2.c8m16',
              vcpu: server.cpu_cores,
              memory_gb: server.ram_gb,
              gpu_count: server.gpu_quantity,
              gpu_type: server.gpu_type !== '-' ? server.gpu_type : undefined
            }
          }))
        }
      };

      console.log('âœ… ë­ì‚¬ AICC ê³„ì‚° ì™„ë£Œ:', {
        totalCpu,
        totalMemory,
        totalGpu,
        totalStorage,
        estimatedCostAWS
      });

      return result;

    } catch (error) {
      console.error('âŒ ë­ì‚¬ AICC ê³„ì‚° ì‹¤íŒ¨:', error);
      
      // [advice from AI] ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ Fallback ì‚¬ìš©
      return this.calculateFallback(requirements, gpuType);
    }
  }

  /**
   * [advice from AI] ê°€ì´ë“œ ê¸°ë°˜ ì •êµí•œ í•˜ë“œì›¨ì–´ ê³„ì‚° ë¡œì§
   * RDC API ê°€ì´ë“œ ë¬¸ì„œì˜ ê³„ì‚° ë°©ì‹ì„ êµ¬í˜„
   */
  calculateFallback(requirements, gpuType = 'auto') {
    console.log('ê°€ì´ë“œ ê¸°ë°˜ í•˜ë“œì›¨ì–´ ê³„ì‚° ì‹¤í–‰');
    
    const {
      callbot = 0,
      chatbot = 0,
      advisor = 0,
      stt = 0,
      tts = 0,
      ta = 0,
      qa = 0
    } = requirements;

    // [advice from AI] ì…ë ¥ê°’ ê²€ì¦ (ê°€ì´ë“œ ê¸°ì¤€)
    const validatedReqs = {
      callbot: Math.max(0, Math.min(callbot, 500)),
      chatbot: Math.max(0, Math.min(chatbot, 2000)),
      advisor: Math.max(0, Math.min(advisor, 1000)),
      stt: Math.max(0, Math.min(stt, 500)),
      tts: Math.max(0, Math.min(tts, 500)),
      ta: Math.max(0, Math.min(ta, 3000)),
      qa: Math.max(0, Math.min(qa, 2000))
    };

    // [advice from AI] GPU íƒ€ì…ë³„ íŠ¹ì„± ì •ì˜ (ê°€ì´ë“œ ê¸°ì¤€)
    const gpuSpecs = {
      'T4': { memory: 16, performance: 1.0, cost_multiplier: 1.0 },
      'V100': { memory: 32, performance: 2.0, cost_multiplier: 1.8 },
      'L40S': { memory: 48, performance: 3.0, cost_multiplier: 2.5 },
      'auto': { memory: 16, performance: 1.0, cost_multiplier: 1.0 }
    };

    const selectedGpu = gpuType === 'auto' ? 'T4' : gpuType;
    const gpuSpec = gpuSpecs[selectedGpu] || gpuSpecs['T4'];

    // [advice from AI] ì •êµí•œ ë¦¬ì†ŒìŠ¤ ê³„ì‚°
    // GPU ìš”êµ¬ì‚¬í•­ (TTS, STT, ì½œë´‡ ìŒì„±ì²˜ë¦¬)
    const gpuLoad = {
      tts: validatedReqs.tts * 0.8,          // TTSëŠ” GPU ì§‘ì•½ì 
      stt: validatedReqs.stt * 0.6,          // STTë„ GPU í•„ìš”
      callbot_voice: validatedReqs.callbot * 0.4  // ì½œë´‡ ìŒì„±ì²˜ë¦¬
    };
    const totalGpuLoad = gpuLoad.tts + gpuLoad.stt + gpuLoad.callbot_voice;
    const gpuCount = Math.max(1, Math.ceil(totalGpuLoad / (10 * gpuSpec.performance)));

    // CPU ìš”êµ¬ì‚¬í•­ (ëª¨ë“  ì„œë¹„ìŠ¤)
    const cpuLoad = {
      callbot: validatedReqs.callbot * 0.2,
      chatbot: validatedReqs.chatbot * 0.1,
      advisor: validatedReqs.advisor * 0.3,
      stt: validatedReqs.stt * 0.15,
      tts: validatedReqs.tts * 0.1,
      ta: validatedReqs.ta * 0.005,
      qa: validatedReqs.qa * 0.003
    };
    const totalCpuLoad = Object.values(cpuLoad).reduce((sum, load) => sum + load, 0);
    const cpuCores = Math.max(4, Math.ceil(totalCpuLoad));

    // ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ (GB)
    const memoryLoad = {
      callbot: validatedReqs.callbot * 0.5,
      chatbot: validatedReqs.chatbot * 0.2,
      advisor: validatedReqs.advisor * 0.8,
      stt: validatedReqs.stt * 0.3,
      tts: validatedReqs.tts * 0.4,
      ta: validatedReqs.ta * 0.01,
      qa: validatedReqs.qa * 0.008
    };
    const totalMemoryLoad = Object.values(memoryLoad).reduce((sum, load) => sum + load, 0);
    const memoryGb = Math.max(8, Math.ceil(totalMemoryLoad));

    // [advice from AI] AWS ì¸ìŠ¤í„´ìŠ¤ ë§¤ì¹­ (ê°€ì´ë“œ ê¸°ì¤€)
    const gpuServers = [];
    const cpuServers = [];
    
    // GPU ì„œë²„ ê³„ì‚°
    if (gpuCount > 0) {
      const gpuInstanceType = selectedGpu === 'V100' ? 'p3.2xlarge' : 
                             selectedGpu === 'L40S' ? 'g5.xlarge' : 'g4dn.xlarge';
      const gpuCostPerInstance = selectedGpu === 'V100' ? 810 : 
                                selectedGpu === 'L40S' ? 1125 : 450;
      
      gpuServers.push({
        type: gpuInstanceType,
        count: gpuCount,
        cpu_cores: 4,
        memory_gb: 16,
        gpu_count: 1,
        gpu_type: selectedGpu,
        monthly_cost_usd: gpuCostPerInstance
      });
    }

    // CPU ì„œë²„ ê³„ì‚°
    const cpuServerCount = Math.max(1, Math.ceil(cpuCores / 8));
    cpuServers.push({
      type: "c5.2xlarge",
      count: cpuServerCount,
      cpu_cores: 8,
      memory_gb: 16,
      monthly_cost_usd: 300
    });

    // ì¸í”„ë¼ ì„œë²„ (ê³ ì •)
    const infraServers = [{
      type: "t3.medium",
      count: 1,
      cpu_cores: 2,
      memory_gb: 4,
      monthly_cost_usd: 50
    }];

    // [advice from AI] ë¹„ìš© ê³„ì‚° (ê°€ì´ë“œ ê¸°ì¤€)
    const gpuCost = gpuServers.reduce((sum, server) => 
      sum + (server.monthly_cost_usd * server.count), 0);
    const cpuCost = cpuServers.reduce((sum, server) => 
      sum + (server.monthly_cost_usd * server.count), 0);
    const infraCost = infraServers.reduce((sum, server) => 
      sum + (server.monthly_cost_usd * server.count), 0);
    
    const totalAwsCost = gpuCost + cpuCost + infraCost;
    const totalNcpCost = totalAwsCost * 1200; // í™˜ìœ¨ ì ìš©

    // ì„œë²„ ìˆ˜ ê³„ì‚°
    const totalServers = gpuCount + cpuServerCount + 1;

    return {
      success: true,
      message: "ê°€ì´ë“œ ê¸°ë°˜ í•˜ë“œì›¨ì–´ ê³„ì‚° ì™„ë£Œ",
      input_data: {
        requirements: validatedReqs,
        gpu_type: gpuType
      },
      hardware_specification: {
        gpu_servers: gpuServers,
        cpu_servers: cpuServers,
        infrastructure_servers: infraServers
      },
      aws_cost_analysis: {
        total_monthly_cost_usd: totalAwsCost,
        breakdown: {
          gpu_servers: gpuCost,
          cpu_servers: cpuCost,
          infrastructure_servers: infraCost
        },
        recommended_instances: [
          ...gpuServers.map(s => s.type),
          ...cpuServers.map(s => s.type),
          ...infraServers.map(s => s.type)
        ]
      },
      ncp_cost_analysis: {
        total_monthly_cost_krw: totalNcpCost,
        breakdown: {
          gpu_servers: gpuCost * 1200,
          cpu_servers: cpuCost * 1200,
          infrastructure_servers: infraCost * 1200
        },
        recommended_instances: ["g2.c2m8", "c2.c4m8", "m2.c2m4"]
      },
      resource_summary: {
        total_gpu_count: gpuCount,
        total_cpu_cores: cpuCores,
        total_memory_gb: memoryGb,
        total_servers: totalServers
      },
      optimization_recommendations: [
        `ì„ íƒëœ GPU: ${selectedGpu} (ë©”ëª¨ë¦¬: ${gpuSpec.memory}GB, ì„±ëŠ¥: ${gpuSpec.performance}x)`,
        `GPU ì„œë²„ ${gpuCount}ëŒ€ë¡œ ${totalGpuLoad.toFixed(1)} ë¡œë“œ ì²˜ë¦¬`,
        `CPU ì„œë²„ ${cpuServerCount}ëŒ€ë¡œ ${totalCpuLoad.toFixed(1)} ë¡œë“œ ì²˜ë¦¬`,
        "ê°€ì´ë“œ ê¸°ì¤€ ì •êµí•œ ê³„ì‚°ìœ¼ë¡œ ë†’ì€ ì •í™•ë„ ë³´ì¥"
      ],
      source: 'embedded_calculator'
    };
  }

  /**
   * [advice from AI] ë©”ì¸ í•˜ë“œì›¨ì–´ ê³„ì‚° í•¨ìˆ˜
   * RDC API ìš°ì„  ì‹œë„ â†’ Fallback ë¡œì§ ì‚¬ìš©
   */
  async calculateHardware(requirements, gpuType = 'auto') {
    try {
      // ì…ë ¥ê°’ ê²€ì¦
      if (!requirements || typeof requirements !== 'object') {
        throw new Error('Requirements ê°ì²´ê°€ í•„ìš”í•©ë‹ˆë‹¤');
      }

      // 1. RDC API ì‹œë„
      const rdcResult = await this.callRDCAPIWithRetry(requirements, gpuType);
      if (rdcResult && rdcResult.success) {
        return rdcResult.data;
      }

      // 2. Fallback ë¡œì§ ì‚¬ìš©
      return this.calculateFallback(requirements, gpuType);
      
    } catch (error) {
      console.error('í•˜ë“œì›¨ì–´ ê³„ì‚° ì˜¤ë¥˜:', error);
      
      // ì—ëŸ¬ ì‹œì—ë„ Fallback ì‹œë„
      try {
        const fallbackResult = this.calculateFallback(requirements, gpuType);
        fallbackResult.error_info = {
          original_error: error.message,
          fallback_used: true
        };
        return fallbackResult;
      } catch (fallbackError) {
        throw new Error(`í•˜ë“œì›¨ì–´ ê³„ì‚° ì‹¤íŒ¨: ${error.message}`);
      }
    }
  }

  /**
   * [advice from AI] ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   */
  async getServiceStatus() {
    const rdcHealthy = await this.checkHealth();
    
    return {
      rdc_api: {
        url: this.baseURL,
        status: rdcHealthy ? 'healthy' : 'unavailable',
        last_checked: new Date().toISOString()
      },
      fallback: {
        status: 'available',
        description: 'Local calculation fallback'
      }
    };
  }
}

module.exports = RDCCalculatorService;
