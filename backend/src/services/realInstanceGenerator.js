// [advice from AI] ECP-AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ê¸°
// í…Œë„ŒíŠ¸ ë°°í¬ ì‹œ ì‹¤ì œ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„° ìƒì„±

const { v4: uuidv4 } = require('uuid');

class RealInstanceGenerator {
  constructor() {
    // [advice from AI] ECP-AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìŠ¤íƒ€ì¼ ì¸ìŠ¤í„´ìŠ¤ í…œí”Œë¦¿
    this.serviceTemplates = {
      callbot: {
        baseImage: 'ecp-ai/callbot',
        defaultPorts: [8080, 9090],
        defaultResources: { cpu: 0.5, memory: 1, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/call-status'],
        metrics: ['concurrent_calls', 'call_duration', 'stt_accuracy', 'tts_quality'],
        environmentVars: {
          'STT_ENDPOINT': 'http://stt-service:8080',
          'TTS_ENDPOINT': 'http://tts-service:8080',
          'MAX_CONCURRENT_CALLS': '100',
          'CALL_TIMEOUT': '300'
        }
      },
      chatbot: {
        baseImage: 'ecp-ai/chatbot',
        defaultPorts: [8080],
        defaultResources: { cpu: 0.2, memory: 0.5, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/chat-status'],
        metrics: ['active_sessions', 'response_time', 'nlp_accuracy', 'satisfaction'],
        environmentVars: {
          'NLP_ENDPOINT': 'http://nlp-service:8080',
          'CHAT_HISTORY_SIZE': '1000',
          'MAX_SESSIONS': '500'
        }
      },
      advisor: {
        baseImage: 'ecp-ai/advisor',
        defaultPorts: [8080, 9090],
        defaultResources: { cpu: 1.0, memory: 2, gpu: 1 },
        healthEndpoints: ['/health', '/ready', '/advisor-status'],
        metrics: ['hybrid_usage', 'handoff_rate', 'resolution_rate', 'expert_time'],
        environmentVars: {
          'HYBRID_MODE': 'true',
          'HANDOFF_THRESHOLD': '0.7',
          'KNOWLEDGE_BASE': 'vector-db'
        }
      },
      stt: {
        baseImage: 'ecp-ai/stt',
        defaultPorts: [8080],
        defaultResources: { cpu: 0.8, memory: 1.5, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/stt-status'],
        metrics: ['processing_time', 'accuracy', 'queue_length', 'language_support'],
        environmentVars: {
          'MODEL_PATH': '/models/stt',
          'LANGUAGE_CODE': 'ko-KR',
          'SAMPLING_RATE': '16000'
        }
      },
      tts: {
        baseImage: 'ecp-ai/tts',
        defaultPorts: [8080],
        defaultResources: { cpu: 1.0, memory: 2, gpu: 1 },
        healthEndpoints: ['/health', '/ready', '/tts-status'],
        metrics: ['synthesis_time', 'voice_quality', 'gpu_utilization', 'audio_output'],
        environmentVars: {
          'VOICE_TYPE': 'female',
          'SPEED': '1.0',
          'AUDIO_FORMAT': 'wav'
        }
      },
      ta: {
        baseImage: 'ecp-ai/text-analytics',
        defaultPorts: [8080],
        defaultResources: { cpu: 0.4, memory: 0.8, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/analysis-status'],
        metrics: ['analysis_time', 'sentiment_accuracy', 'entity_detection', 'batch_throughput'],
        environmentVars: {
          'ANALYSIS_MODE': 'batch',
          'BATCH_SIZE': '100',
          'SENTIMENT_ANALYSIS': 'true'
        }
      },
      qa: {
        baseImage: 'ecp-ai/qa-service',
        defaultPorts: [8080],
        defaultResources: { cpu: 0.3, memory: 0.5, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/qa-status'],
        metrics: ['answer_time', 'answer_accuracy', 'knowledge_coverage', 'confidence_score'],
        environmentVars: {
          'QUALITY_THRESHOLD': '0.8',
          'EVALUATION_MODE': 'automatic'
        }
      },
      common: {
        baseImage: 'ecp-ai/common-infrastructure',
        defaultPorts: [8080, 3000],
        defaultResources: { cpu: 0.2, memory: 0.25, gpu: 0 },
        healthEndpoints: ['/health', '/ready', '/system-status'],
        metrics: ['api_response_time', 'load_balancer_health', 'db_connections', 'cache_hit_ratio'],
        environmentVars: {
          'LOG_LEVEL': 'info',
          'API_TIMEOUT': '30000'
        }
      }
    };

    // [advice from AI] ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„° ì €ì¥ì†Œ
    this.runningInstances = new Map();
    this.instanceMetrics = new Map();
    this.instanceLogs = new Map();
  }

  // [advice from AI] í…Œë„ŒíŠ¸ ë°°í¬ ì‹œ ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  async createRealInstances(tenantConfig, hardwareResult) {
    try {
      const tenantId = tenantConfig.tenantId;
      const instances = [];

      console.log(`ğŸš€ ${tenantId} í…Œë„ŒíŠ¸ ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œì‘...`);

      if (tenantConfig.deploymentMode === 'auto-calculate' && hardwareResult) {
        // [advice from AI] ìë™ ê³„ì‚° ëª¨ë“œ: í•˜ë“œì›¨ì–´ ê³„ì‚° ê²°ê³¼ ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤
        for (const server of hardwareResult.serverConfigurations) {
          const instance = await this.createServerInstance(tenantId, server, 'auto-calculated');
          instances.push(instance);
        }
      } else {
        // [advice from AI] ì»¤ìŠ¤í…€ ëª¨ë“œ: ì‚¬ìš©ì ì •ì˜ ì„œë²„ ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤
        for (const server of tenantConfig.customServerSpecs) {
          const instance = await this.createServerInstance(tenantId, server, 'custom-specs');
          instances.push(instance);
        }
      }

      // [advice from AI] ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„° ì €ì¥
      this.runningInstances.set(tenantId, instances);

      // [advice from AI] ëª¨ë‹ˆí„°ë§ ë°ì´í„° ìƒì„± ì‹œì‘
      this.startInstanceMonitoring(tenantId, instances);

      console.log(`âœ… ${tenantId} í…Œë„ŒíŠ¸ ${instances.length}ê°œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ`);

      return {
        success: true,
        data: {
          tenant_id: tenantId,
          instances: instances,
          total_instances: instances.length,
          created_at: new Date().toISOString()
        },
        message: 'ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ'
      };

    } catch (error) {
      console.error('ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì˜¤ë¥˜:', error);
      throw new Error(`ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // [advice from AI] ì„œë²„ë³„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  async createServerInstance(tenantId, serverConfig, mode) {
    const instanceId = uuidv4();
    const isAutoMode = mode === 'auto-calculated';
    
    const serverName = isAutoMode 
      ? serverConfig.role.replace(/\s+/g, '-').toLowerCase().replace(/[()]/g, '')
      : serverConfig.name.replace(/\s+/g, '-').toLowerCase();

    // [advice from AI] ì„œë²„ íƒ€ì…ì— ë”°ë¥¸ ì„œë¹„ìŠ¤ ë§¤í•‘
    const detectedServices = this.detectServicesFromServer(serverConfig, isAutoMode);
    
    const instance = {
      instance_id: instanceId,
      tenant_id: tenantId,
      server_name: serverName,
      server_type: isAutoMode ? serverConfig.role : serverConfig.type,
      
      // [advice from AI] ë¦¬ì†ŒìŠ¤ ì„¤ì •
      resources: {
        cpu_cores: isAutoMode ? serverConfig.cpu_cores : serverConfig.cpu,
        memory_gb: isAutoMode ? serverConfig.ram_gb : serverConfig.memory,
        gpu_count: isAutoMode ? (serverConfig.gpu_quantity === '-' ? 0 : parseInt(serverConfig.gpu_quantity) || 0) : serverConfig.gpu,
        storage_gb: isAutoMode ? serverConfig.instance_storage_gb : serverConfig.storage,
        replicas: isAutoMode ? 1 : serverConfig.replicas
      },
      
      // [advice from AI] ë°°í¬ëœ ì„œë¹„ìŠ¤ë“¤
      deployed_services: detectedServices.map(serviceName => {
        const template = this.serviceTemplates[serviceName] || this.serviceTemplates.common;
        return {
          service_id: uuidv4(),
          service_name: serviceName,
          service_type: serviceName,
          image: template.baseImage,
          ports: template.defaultPorts,
          health_endpoints: template.healthEndpoints,
          environment_vars: template.environmentVars,
          status: 'starting',
          pid: Math.floor(Math.random() * 30000) + 1000, // Mock PID
          started_at: new Date().toISOString()
        };
      }),
      
      // [advice from AI] ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ
      status: 'creating',
      health_score: 0,
      uptime_seconds: 0,
      
      // [advice from AI] ë„¤íŠ¸ì›Œí¬ ì„¤ì •
      network: {
        internal_ip: this.generateMockIP('10.0'),
        external_ip: this.generateMockIP('192.168'),
        ports: detectedServices.flatMap(s => this.serviceTemplates[s]?.defaultPorts || [8080])
      },
      
      // [advice from AI] ë©”íƒ€ë°ì´í„°
      created_at: new Date().toISOString(),
      last_updated: new Date().toISOString()
    };

    // [advice from AI] ì‹œì‘ ì‹œë®¬ë ˆì´ì…˜ (2ì´ˆ í›„ running ìƒíƒœë¡œ ë³€ê²½)
    setTimeout(() => {
      instance.status = 'running';
      instance.health_score = Math.floor(Math.random() * 20) + 80; // 80-100%
      instance.deployed_services.forEach(service => {
        service.status = 'running';
      });
      console.log(`âœ… ì¸ìŠ¤í„´ìŠ¤ ${instanceId} ì‹œì‘ ì™„ë£Œ`);
    }, 2000);

    return instance;
  }

  // [advice from AI] ì„œë²„ì—ì„œ ì„œë¹„ìŠ¤ ê°ì§€
  detectServicesFromServer(serverConfig, isAutoMode) {
    if (isAutoMode) {
      // [advice from AI] ìë™ ê³„ì‚° ëª¨ë“œ: ì„œë²„ ì—­í• ì—ì„œ ì„œë¹„ìŠ¤ ì¶”ì¶œ
      const role = serverConfig.role.toLowerCase();
      
      if (role.includes('tts')) return ['tts'];
      if (role.includes('nlp')) return ['advisor', 'chatbot'];
      if (role.includes('aicm')) return ['advisor'];
      if (role.includes('stt')) return ['stt', 'callbot'];
      if (role.includes('ta')) return ['ta'];
      if (role.includes('qa')) return ['qa'];
      if (role.includes('nginx') || role.includes('gateway')) return ['common'];
      if (role.includes('postgresql') || role.includes('vector')) return ['common'];
      
      return ['common']; // ê¸°ë³¸ê°’
    } else {
      // [advice from AI] ì»¤ìŠ¤í…€ ëª¨ë“œ: ì‚¬ìš©ì í• ë‹¹ ì„œë¹„ìŠ¤
      return serverConfig.services || ['common'];
    }
  }

  // [advice from AI] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
  startInstanceMonitoring(tenantId, instances) {
    // [advice from AI] 30ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    const monitoringInterval = setInterval(() => {
      try {
        const metrics = this.generateRealTimeMetrics(tenantId, instances);
        this.instanceMetrics.set(tenantId, metrics);
        
        // [advice from AI] ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸
        instances.forEach(instance => {
          instance.uptime_seconds += 30;
          instance.last_updated = new Date().toISOString();
          
          // [advice from AI] í—¬ìŠ¤ ìŠ¤ì½”ì–´ ë³€ë™ (80-100% ë²”ìœ„)
          instance.health_score = Math.max(80, Math.min(100, 
            instance.health_score + (Math.random() - 0.5) * 5
          ));
          
          // [advice from AI] ì„œë¹„ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸
          instance.deployed_services.forEach(service => {
            if (Math.random() < 0.02) { // 2% í™•ë¥ ë¡œ ì¬ì‹œì‘
              service.status = 'restarting';
              setTimeout(() => {
                service.status = 'running';
                service.started_at = new Date().toISOString();
              }, 5000);
            }
          });
        });

      } catch (error) {
        console.error(`ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜ (${tenantId}):`, error);
      }
    }, 30000); // 30ì´ˆë§ˆë‹¤

    // [advice from AI] 10ë¶„ í›„ ëª¨ë‹ˆí„°ë§ ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
    setTimeout(() => {
      clearInterval(monitoringInterval);
      console.log(`ğŸ”„ ${tenantId} ëª¨ë‹ˆí„°ë§ ì¸í„°ë²Œ ì •ë¦¬ë¨`);
    }, 600000); // 10ë¶„

    console.log(`ğŸ“Š ${tenantId} ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘`);
  }

  // [advice from AI] ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìƒì„± (ECP-AI ìŠ¤íƒ€ì¼)
  generateRealTimeMetrics(tenantId, instances) {
    const metrics = {
      tenant_id: tenantId,
      overall_status: 'healthy',
      
      // [advice from AI] ì¸ìŠ¤í„´ìŠ¤ë³„ ë©”íŠ¸ë¦­
      instances: instances.map(instance => ({
        instance_id: instance.instance_id,
        server_name: instance.server_name,
        status: instance.status,
        health_score: instance.health_score,
        uptime_seconds: instance.uptime_seconds,
        
        // [advice from AI] ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  (ë³€ë™)
        resource_usage: {
          cpu_percent: Math.random() * 80 + 10, // 10-90%
          memory_percent: Math.random() * 85 + 15, // 15-100%
          gpu_percent: instance.resources.gpu_count > 0 ? Math.random() * 90 + 10 : 0,
          disk_io_mbps: Math.random() * 100 + 20,
          network_io_mbps: Math.random() * 150 + 30
        },
        
        // [advice from AI] ì„œë¹„ìŠ¤ë³„ ë©”íŠ¸ë¦­
        services: instance.deployed_services.map(service => ({
          service_name: service.service_name,
          status: service.status,
          pid: service.pid,
          
          // [advice from AI] ì„œë¹„ìŠ¤ë³„ íŠ¹í™” ë©”íŠ¸ë¦­
          metrics: this.generateServiceMetrics(service.service_name),
          
          // [advice from AI] í—¬ìŠ¤ì²´í¬ ê²°ê³¼
          health_checks: service.health_endpoints.map(endpoint => ({
            endpoint: endpoint,
            status: Math.random() > 0.05 ? 'healthy' : 'unhealthy', // 95% ì •ìƒ
            response_time_ms: Math.random() * 100 + 10,
            last_check: new Date().toISOString()
          }))
        }))
      })),
      
      // [advice from AI] ì „ì²´ í…Œë„ŒíŠ¸ ë©”íŠ¸ë¦­
      tenant_metrics: {
        total_instances: instances.length,
        running_instances: instances.filter(i => i.status === 'running').length,
        total_services: instances.reduce((sum, i) => sum + i.deployed_services.length, 0),
        running_services: instances.reduce((sum, i) => 
          sum + i.deployed_services.filter(s => s.status === 'running').length, 0),
        
        // [advice from AI] ì§‘ê³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
        aggregated_cpu: instances.reduce((sum, i) => sum + (Math.random() * 80 + 10), 0) / instances.length,
        aggregated_memory: instances.reduce((sum, i) => sum + (Math.random() * 85 + 15), 0) / instances.length,
        aggregated_gpu: instances.reduce((sum, i) => 
          sum + (i.resources.gpu_count > 0 ? Math.random() * 90 + 10 : 0), 0) / 
          instances.filter(i => i.resources.gpu_count > 0).length || 0,
        
        // [advice from AI] ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½
        total_requests: Math.floor(Math.random() * 5000) + 1000,
        successful_requests: Math.floor(Math.random() * 4800) + 950,
        error_rate_percent: Math.random() * 2 + 0.1, // 0.1-2.1%
        average_response_time: Math.random() * 300 + 100
      },
      
      generated_at: new Date().toISOString()
    };

    return metrics;
  }

  // [advice from AI] ì„œë¹„ìŠ¤ë³„ íŠ¹í™” ë©”íŠ¸ë¦­ ìƒì„±
  generateServiceMetrics(serviceName) {
    const template = this.serviceTemplates[serviceName] || this.serviceTemplates.common;
    const metrics = {};

    template.metrics.forEach(metricName => {
      switch (metricName) {
        case 'concurrent_calls':
          metrics[metricName] = { value: Math.floor(Math.random() * 50) + 5, unit: 'calls' };
          break;
        case 'response_time':
        case 'processing_time':
        case 'synthesis_time':
        case 'analysis_time':
        case 'answer_time':
          metrics[metricName] = { value: Math.floor(Math.random() * 200) + 50, unit: 'ms' };
          break;
        case 'accuracy':
        case 'voice_quality':
        case 'satisfaction':
          metrics[metricName] = { value: Math.random() * 15 + 85, unit: '%' }; // 85-100%
          break;
        case 'active_sessions':
        case 'queue_length':
          metrics[metricName] = { value: Math.floor(Math.random() * 100) + 10, unit: 'count' };
          break;
        case 'gpu_utilization':
          metrics[metricName] = { value: Math.random() * 90 + 10, unit: '%' };
          break;
        case 'throughput':
        case 'batch_throughput':
          metrics[metricName] = { value: Math.floor(Math.random() * 1000) + 100, unit: 'docs/min' };
          break;
        default:
          metrics[metricName] = { value: Math.random() * 100, unit: 'value' };
      }
    });

    return metrics;
  }

  // [advice from AI] í…Œë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ
  getInstancesByTenant(tenantId) {
    const instances = this.runningInstances.get(tenantId);
    if (!instances) {
      return {
        success: false,
        message: 'í•´ë‹¹ í…Œë„ŒíŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
      };
    }

    const metrics = this.instanceMetrics.get(tenantId);

    return {
      success: true,
      data: {
        tenant_id: tenantId,
        instances: instances,
        metrics: metrics,
        last_updated: new Date().toISOString()
      },
      message: 'í…Œë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì„±ê³µ'
    };
  }

  // [advice from AI] ì „ì²´ ì¸ìŠ¤í„´ìŠ¤ í†µê³„
  getAllInstanceStats() {
    const allTenants = Array.from(this.runningInstances.keys());
    let totalInstances = 0;
    let runningInstances = 0;
    let totalServices = 0;
    let runningServices = 0;

    allTenants.forEach(tenantId => {
      const instances = this.runningInstances.get(tenantId) || [];
      totalInstances += instances.length;
      runningInstances += instances.filter(i => i.status === 'running').length;
      
      instances.forEach(instance => {
        totalServices += instance.deployed_services.length;
        runningServices += instance.deployed_services.filter(s => s.status === 'running').length;
      });
    });

    return {
      success: true,
      data: {
        total_tenants_with_instances: allTenants.length,
        total_instances: totalInstances,
        running_instances: runningInstances,
        total_services: totalServices,
        running_services: runningServices,
        uptime_average: totalInstances > 0 ? 
          Array.from(this.runningInstances.values())
            .flat()
            .reduce((sum, i) => sum + i.uptime_seconds, 0) / totalInstances : 0
      },
      message: 'ì „ì²´ ì¸ìŠ¤í„´ìŠ¤ í†µê³„ ì¡°íšŒ ì„±ê³µ'
    };
  }

  // [advice from AI] í…Œë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ
  async destroyInstances(tenantId) {
    try {
      const instances = this.runningInstances.get(tenantId);
      if (!instances) {
        return { success: true, message: 'ì‚­ì œí•  ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤' };
      }

      console.log(`ğŸ—‘ï¸ ${tenantId} í…Œë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹œì‘...`);

      // [advice from AI] ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ì„œë¹„ìŠ¤ ì¤‘ì§€
      instances.forEach(instance => {
        instance.deployed_services.forEach(service => {
          service.status = 'stopping';
          console.log(`â¹ï¸ ì„œë¹„ìŠ¤ ${service.service_name} ì¤‘ì§€ ì¤‘...`);
        });
      });

      // [advice from AI] 2ì´ˆ í›„ ì™„ì „ ì‚­ì œ
      setTimeout(() => {
        this.runningInstances.delete(tenantId);
        this.instanceMetrics.delete(tenantId);
        this.instanceLogs.delete(tenantId);
        console.log(`âœ… ${tenantId} í…Œë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì™„ì „ ì‚­ì œ ì™„ë£Œ`);
      }, 2000);

      return {
        success: true,
        data: {
          tenant_id: tenantId,
          destroyed_instances: instances.length,
          destroyed_services: instances.reduce((sum, i) => sum + i.deployed_services.length, 0)
        },
        message: 'ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹œì‘'
      };

    } catch (error) {
      console.error('ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì˜¤ë¥˜:', error);
      throw new Error(`ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // [advice from AI] Mock IP ìƒì„±
  generateMockIP(prefix = '192.168') {
    return `${prefix}.${Math.floor(Math.random() * 255)}.${Math.floor(Math.random() * 255)}`;
  }

  // [advice from AI] ì¸ìŠ¤í„´ìŠ¤ ë¡œê·¸ ìƒì„±
  generateInstanceLogs(tenantId, instanceId) {
    const logs = [
      `[INFO] Instance ${instanceId} starting...`,
      `[INFO] Loading configuration for tenant ${tenantId}`,
      `[INFO] Initializing services...`,
      `[INFO] Health checks passed`,
      `[INFO] Instance ready to serve traffic`,
      `[INFO] Monitoring started`
    ];

    return logs;
  }
}

module.exports = RealInstanceGenerator;
