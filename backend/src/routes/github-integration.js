// [advice from AI] GitHub í†µí•© API
// ë¬¸ì„œ ê°€ì´ë“œ: GitHub ë„¤ì´í‹°ë¸Œ ìš°ì„  ì „ëµìœ¼ë¡œ ì™„ì „í•œ GitHub API í™œìš©

const express = require('express');
const router = express.Router();
const axios = require('axios');
const { Pool } = require('pg');
const { v4: uuidv4 } = require('uuid');
const { verifyToken, checkPermission } = require('../middleware/jwtAuth');

// PostgreSQL ì—°ê²°
const pool = new Pool({
  user: process.env.DB_USER || 'postgres',
  host: process.env.DB_HOST || 'localhost',
  database: process.env.DB_NAME || 'timbel_knowledge',
  password: process.env.DB_PASSWORD || 'password',
  port: process.env.DB_PORT || 5432,
});

// GitHub API ì„¤ì •
const GITHUB_TOKEN = process.env.GITHUB_TOKEN;
const GITHUB_API_BASE = 'https://api.github.com';

// [advice from AI] GitHub API í—¬í¼ í´ë˜ìŠ¤ (ë¬¸ì„œ ê°€ì´ë“œ ê¸°ë°˜)
class GitHubEnhancedAPI {
  constructor(token) {
    this.token = token;
    this.headers = {
      'Authorization': `token ${token}`,
      'Accept': 'application/vnd.github.v3+json',
      'User-Agent': 'Timbel-Platform'
    };
  }

  // ë ˆí¬ì§€í† ë¦¬ ë©”íƒ€ë°ì´í„° ì‹¤ì‹œê°„ ë™ê¸°í™”
  async syncRepositoryMetadata(repoFullName) {
    try {
      console.log(`ğŸ” GitHub ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘: ${repoFullName}`);
      
      const [owner, repo] = repoFullName.split('/');
      
      // ë³‘ë ¬ë¡œ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
      const [
        repository,
        branches,
        commits,
        pullRequests,
        issues,
        releases,
        contents,
        workflows
      ] = await Promise.all([
        this.getRepository(owner, repo),
        this.getBranches(owner, repo),
        this.getCommits(owner, repo, { per_page: 100 }),
        this.getPullRequests(owner, repo, { state: 'all', per_page: 50 }),
        this.getIssues(owner, repo, { state: 'all', per_page: 50 }),
        this.getReleases(owner, repo),
        this.getRepositoryContents(owner, repo),
        this.getWorkflows(owner, repo)
      ]);

      return this.aggregateMetadata({
        repository,
        branches,
        commits,
        pullRequests,
        issues,
        releases,
        contents,
        workflows
      });
      
    } catch (error) {
      console.error('âŒ GitHub ë©”íƒ€ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // ê°œë³„ API í˜¸ì¶œ ë©”ì„œë“œë“¤
  async getRepository(owner, repo) {
    const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}`, {
      headers: this.headers
    });
    return response.data;
  }

  async getBranches(owner, repo) {
    const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/branches`, {
      headers: this.headers,
      params: { per_page: 100 }
    });
    return response.data;
  }

  async getCommits(owner, repo, params = {}) {
    const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/commits`, {
      headers: this.headers,
      params: { per_page: 100, ...params }
    });
    return response.data;
  }

  async getPullRequests(owner, repo, params = {}) {
    const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/pulls`, {
      headers: this.headers,
      params: { per_page: 50, ...params }
    });
    return response.data;
  }

  async getIssues(owner, repo, params = {}) {
    const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/issues`, {
      headers: this.headers,
      params: { per_page: 50, ...params }
    });
    return response.data;
  }

  async getReleases(owner, repo) {
    try {
      const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/releases`, {
        headers: this.headers,
        params: { per_page: 50 }
      });
      return response.data;
    } catch (error) {
      return []; // ë¦´ë¦¬ì¦ˆê°€ ì—†ëŠ” ê²½ìš°
    }
  }

  async getRepositoryContents(owner, repo, path = '') {
    try {
      const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/contents/${path}`, {
        headers: this.headers
      });
      return response.data;
    } catch (error) {
      return [];
    }
  }

  async getWorkflows(owner, repo) {
    try {
      const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/actions/workflows`, {
        headers: this.headers
      });
      return response.data.workflows || [];
    } catch (error) {
      return [];
    }
  }

  // ë©”íƒ€ë°ì´í„° ì§‘ê³„ ë° ë¶„ì„
  aggregateMetadata(data) {
    const { repository, branches, commits, pullRequests, issues, releases, contents, workflows } = data;

    // CI/CD íŒ¨í„´ ë¶„ì„
    const cicdPatterns = this.analyzeCICDPatterns(contents, workflows);
    
    // ì½”ë“œ í’ˆì§ˆ ë¶„ì„
    const codeQuality = this.analyzeCodeQuality(commits, pullRequests);
    
    // ë©”íŠ¸ë¦­ ê³„ì‚°
    const metrics = this.calculateMetrics(commits, pullRequests, issues, releases);
    
    // ì¶”ì²œì‚¬í•­ ìƒì„±
    const recommendations = this.generateRecommendations(cicdPatterns, codeQuality, metrics);

    return {
      repository: {
        name: repository.name,
        fullName: repository.full_name,
        description: repository.description,
        language: repository.language,
        stars: repository.stargazers_count,
        forks: repository.forks_count,
        size: repository.size,
        defaultBranch: repository.default_branch,
        isPrivate: repository.private,
        createdAt: repository.created_at,
        updatedAt: repository.updated_at
      },
      branches: branches.map(branch => ({
        name: branch.name,
        protected: branch.protected,
        lastCommit: {
          sha: branch.commit.sha,
          message: branch.commit.commit.message,
          author: branch.commit.commit.author.name,
          date: branch.commit.commit.author.date
        }
      })),
      cicdPatterns,
      codeQuality,
      metrics,
      recommendations
    };
  }

  // CI/CD íŒ¨í„´ ë¶„ì„
  analyzeCICDPatterns(contents, workflows) {
    const fileNames = Array.isArray(contents) ? contents.map(item => item.name.toLowerCase()) : [];
    
    return {
      hasGithubActions: workflows.length > 0,
      hasJenkinsfile: fileNames.includes('jenkinsfile') || fileNames.includes('jenkins'),
      hasDockerfile: fileNames.includes('dockerfile'),
      hasDockerCompose: fileNames.some(name => name.includes('docker-compose')),
      hasKubernetesManifests: fileNames.some(name => name.includes('k8s') || name.includes('kubernetes')),
      hasArgocdConfig: fileNames.some(name => name.includes('argocd') || name.includes('argo')),
      workflows: workflows.map(workflow => workflow.name)
    };
  }

  // ì½”ë“œ í’ˆì§ˆ ë¶„ì„
  analyzeCodeQuality(commits, pullRequests) {
    const recentCommits = commits.slice(0, 50);
    const avgCommitMessageLength = recentCommits.reduce((sum, commit) => 
      sum + (commit.commit.message?.length || 0), 0) / recentCommits.length;
    
    const mergedPRs = pullRequests.filter(pr => pr.merged_at);
    const avgPRSize = mergedPRs.reduce((sum, pr) => sum + (pr.additions + pr.deletions || 0), 0) / mergedPRs.length;

    return {
      commitQualityScore: Math.min(100, (avgCommitMessageLength / 50) * 100),
      prSizeScore: avgPRSize < 500 ? 100 : Math.max(0, 100 - ((avgPRSize - 500) / 50)),
      collaborationScore: pullRequests.length > 0 ? Math.min(100, (mergedPRs.length / pullRequests.length) * 100) : 0
    };
  }

  // ë©”íŠ¸ë¦­ ê³„ì‚°
  calculateMetrics(commits, pullRequests, issues, releases) {
    const contributors = new Set(commits.map(commit => commit.author?.login).filter(Boolean));
    
    return {
      commits: commits.length,
      contributors: contributors.size,
      pullRequests: pullRequests.length,
      issues: issues.filter(issue => !issue.pull_request).length, // ì‹¤ì œ ì´ìŠˆë§Œ ì¹´ìš´íŠ¸
      releases: releases.length
    };
  }

  // ì¶”ì²œì‚¬í•­ ìƒì„±
  generateRecommendations(cicdPatterns, codeQuality, metrics) {
    const recommendations = [];

    // CI/CD ê´€ë ¨ ì¶”ì²œ
    if (!cicdPatterns.hasGithubActions) {
      recommendations.push({
        type: 'cicd',
        title: 'GitHub Actions ì›Œí¬í”Œë¡œìš° ì¶”ê°€',
        description: 'CI/CD ìë™í™”ë¥¼ ìœ„í•´ GitHub Actions ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        priority: 'high'
      });
    }

    if (!cicdPatterns.hasDockerfile) {
      recommendations.push({
        type: 'cicd',
        title: 'Dockerfile ì¶”ê°€',
        description: 'ì»¨í…Œì´ë„ˆí™”ë¥¼ ìœ„í•´ Dockerfileì„ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        priority: 'medium'
      });
    }

    // ì½”ë“œ í’ˆì§ˆ ê´€ë ¨ ì¶”ì²œ
    if (codeQuality.commitQualityScore < 60) {
      recommendations.push({
        type: 'quality',
        title: 'ì»¤ë°‹ ë©”ì‹œì§€ í’ˆì§ˆ ê°œì„ ',
        description: 'ë” ìƒì„¸í•˜ê³  ì˜ë¯¸ìˆëŠ” ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        priority: 'medium'
      });
    }

    if (codeQuality.collaborationScore < 50) {
      recommendations.push({
        type: 'quality',
        title: 'ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°œì„ ',
        description: 'Pull Request ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ë¥¼ ê°•í™”í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        priority: 'high'
      });
    }

    // ë³´ì•ˆ ê´€ë ¨ ì¶”ì²œ
    if (metrics.releases === 0) {
      recommendations.push({
        type: 'security',
        title: 'ë¦´ë¦¬ì¦ˆ ê´€ë¦¬ ì²´ê³„ êµ¬ì¶•',
        description: 'ì •ê¸°ì ì¸ ë¦´ë¦¬ì¦ˆë¥¼ í†µí•œ ë²„ì „ ê´€ë¦¬ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        priority: 'low'
      });
    }

    return recommendations;
  }

  // DORA ë©”íŠ¸ë¦­ ìë™ ê³„ì‚°
  async calculateDORAMetrics(owner, repo) {
    try {
      const [deployments, commits, incidents] = await Promise.all([
        this.getDeployments(owner, repo),
        this.getCommits(owner, repo, { since: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString() }),
        this.getIssues(owner, repo, { labels: 'bug,incident', state: 'all' })
      ]);

      return {
        deploymentFrequency: this.calculateDeploymentFrequency(deployments),
        leadTime: this.calculateLeadTime(commits, deployments),
        mttr: this.calculateMTTR(incidents),
        changeFailureRate: this.calculateChangeFailureRate(deployments)
      };
    } catch (error) {
      console.error('âŒ DORA ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨:', error);
      return null;
    }
  }

  async getDeployments(owner, repo) {
    try {
      const response = await axios.get(`${GITHUB_API_BASE}/repos/${owner}/${repo}/deployments`, {
        headers: this.headers,
        params: { per_page: 100 }
      });
      return response.data;
    } catch (error) {
      return [];
    }
  }

  calculateDeploymentFrequency(deployments) {
    const thirtyDaysAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);
    const recentDeployments = deployments.filter(d => new Date(d.created_at) > thirtyDaysAgo);
    return recentDeployments.length / 30; // ì¼ì¼ í‰ê·  ë°°í¬ íšŸìˆ˜
  }

  calculateLeadTime(commits, deployments) {
    if (commits.length === 0 || deployments.length === 0) return 0;
    
    // ê°„ë‹¨í•œ ë¦¬ë“œ íƒ€ì„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
    const avgCommitToDeployTime = 24 * 60; // 24ì‹œê°„ì„ ë¶„ìœ¼ë¡œ (Mock ë°ì´í„°)
    return avgCommitToDeployTime;
  }

  calculateMTTR(incidents) {
    const resolvedIncidents = incidents.filter(issue => issue.closed_at);
    if (resolvedIncidents.length === 0) return 0;

    const totalResolutionTime = resolvedIncidents.reduce((sum, issue) => {
      const createdAt = new Date(issue.created_at);
      const closedAt = new Date(issue.closed_at);
      return sum + (closedAt.getTime() - createdAt.getTime());
    }, 0);

    return totalResolutionTime / resolvedIncidents.length / (1000 * 60); // ë¶„ ë‹¨ìœ„
  }

  calculateChangeFailureRate(deployments) {
    if (deployments.length === 0) return 0;
    
    // ì‹¤ì œë¡œëŠ” ë°°í¬ ìƒíƒœë¥¼ í™•ì¸í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” Mock ë°ì´í„°
    const failedDeployments = deployments.filter(d => d.description?.includes('failed')).length;
    return (failedDeployments / deployments.length) * 100;
  }
}

// [advice from AI] GitHub ì €ì¥ì†Œ ë¶„ì„ API
router.post('/analyze-repository', verifyToken, async (req, res) => {
  try {
    console.log('ğŸ” GitHub ì €ì¥ì†Œ ë¶„ì„ ìš”ì²­ ìˆ˜ì‹ ...');
    
    const { repositoryUrl } = req.body;
    
    if (!repositoryUrl) {
      return res.status(400).json({
        success: false,
        message: 'GitHub ì €ì¥ì†Œ URLì´ í•„ìš”í•©ë‹ˆë‹¤.'
      });
    }

    // GitHub URLì—ì„œ owner/repo ì¶”ì¶œ
    const githubUrlPattern = /github\.com\/([^\/]+)\/([^\/]+)/;
    const match = repositoryUrl.match(githubUrlPattern);
    
    if (!match) {
      return res.status(400).json({
        success: false,
        message: 'ì˜¬ë°”ë¥¸ GitHub ì €ì¥ì†Œ URLì´ ì•„ë‹™ë‹ˆë‹¤.'
      });
    }

    const [, owner, repo] = match;
    const repoFullName = `${owner}/${repo.replace('.git', '')}`;

    if (!GITHUB_TOKEN) {
      return res.status(500).json({
        success: false,
        message: 'GitHub í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
      });
    }

    // GitHub API í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    const githubAPI = new GitHubEnhancedAPI(GITHUB_TOKEN);
    
    // ì €ì¥ì†Œ ë¶„ì„ ì‹¤í–‰
    const analysis = await githubAPI.syncRepositoryMetadata(repoFullName);
    
    // ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì„ íƒì )
    try {
      const saveQuery = `
        INSERT INTO github_repository_analysis (
          repository_url, repository_name, analysis_data, created_at
        ) VALUES ($1, $2, $3, NOW())
        ON CONFLICT (repository_url) 
        DO UPDATE SET 
          analysis_data = $3, 
          updated_at = NOW()
      `;
      
      await pool.query(saveQuery, [
        repositoryUrl,
        repoFullName,
        JSON.stringify(analysis)
      ]);
      
      console.log(`âœ… ì €ì¥ì†Œ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ${repoFullName}`);
    } catch (dbError) {
      console.warn('âš ï¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ (ë¶„ì„ì€ ì„±ê³µ):', dbError.message);
    }

    res.json({
      success: true,
      data: analysis,
      message: `ì €ì¥ì†Œ '${repoFullName}' ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.`
    });
    
  } catch (error) {
    console.error('âŒ GitHub ì €ì¥ì†Œ ë¶„ì„ ì‹¤íŒ¨:', error);
    
    if (error.response?.status === 404) {
      res.status(404).json({
        success: false,
        message: 'ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
      });
    } else if (error.response?.status === 403) {
      res.status(403).json({
        success: false,
        message: 'GitHub API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. í† í°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
      });
    } else {
      res.status(500).json({
        success: false,
        message: 'ì €ì¥ì†Œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        error: error.message
      });
    }
  }
});

// [advice from AI] DORA ë©”íŠ¸ë¦­ ê³„ì‚° API
router.post('/calculate-dora-metrics', verifyToken, async (req, res) => {
  try {
    console.log('ğŸ“Š DORA ë©”íŠ¸ë¦­ ê³„ì‚° ìš”ì²­ ìˆ˜ì‹ ...');
    
    const { repositoryUrl } = req.body;
    
    if (!repositoryUrl) {
      return res.status(400).json({
        success: false,
        message: 'GitHub ì €ì¥ì†Œ URLì´ í•„ìš”í•©ë‹ˆë‹¤.'
      });
    }

    const githubUrlPattern = /github\.com\/([^\/]+)\/([^\/]+)/;
    const match = repositoryUrl.match(githubUrlPattern);
    
    if (!match) {
      return res.status(400).json({
        success: false,
        message: 'ì˜¬ë°”ë¥¸ GitHub ì €ì¥ì†Œ URLì´ ì•„ë‹™ë‹ˆë‹¤.'
      });
    }

    const [, owner, repo] = match;
    
    if (!GITHUB_TOKEN) {
      return res.status(500).json({
        success: false,
        message: 'GitHub í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
      });
    }

    const githubAPI = new GitHubEnhancedAPI(GITHUB_TOKEN);
    const doraMetrics = await githubAPI.calculateDORAMetrics(owner, repo.replace('.git', ''));
    
    res.json({
      success: true,
      data: doraMetrics,
      message: 'DORA ë©”íŠ¸ë¦­ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
    });
    
  } catch (error) {
    console.error('âŒ DORA ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨:', error);
    res.status(500).json({
      success: false,
      message: 'DORA ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      error: error.message
    });
  }
});

// [advice from AI] GitHub ì €ì¥ì†Œ ëª©ë¡ ì¡°íšŒ API
router.get('/repositories', verifyToken, async (req, res) => {
  try {
    console.log('ğŸ“‹ GitHub ì €ì¥ì†Œ ëª©ë¡ ì¡°íšŒ...');
    
    const query = `
      SELECT 
        repository_url,
        repository_name,
        analysis_data,
        created_at,
        updated_at
      FROM github_repository_analysis 
      ORDER BY updated_at DESC
      LIMIT 50
    `;
    
    const result = await pool.query(query);
    
    res.json({
      success: true,
      data: result.rows,
      message: 'ì €ì¥ì†Œ ëª©ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.'
    });
    
  } catch (error) {
    console.error('âŒ ì €ì¥ì†Œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
    res.status(500).json({
      success: false,
      message: 'ì €ì¥ì†Œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      error: error.message
    });
  }
});

// [advice from AI] GitHub Actions ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¡°íšŒ API
router.get('/workflow-templates', verifyToken, async (req, res) => {
  try {
    console.log('ğŸ“‹ GitHub Actions ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¡°íšŒ...');
    
    // ë‚´ì¥ í…œí”Œë¦¿ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ)
    const templates = [
      {
        id: 'nodejs-basic',
        name: 'Node.js ê¸°ë³¸ CI/CD',
        description: 'Node.js í”„ë¡œì íŠ¸ìš© ê¸°ë³¸ CI/CD íŒŒì´í”„ë¼ì¸',
        language: 'javascript',
        framework: 'nodejs',
        triggers: ['push', 'pull_request'],
        jenkinsIntegration: true,
        ecp_ai_integration: true
      },
      {
        id: 'python-django',
        name: 'Python Django CI/CD',
        description: 'Django ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ìš© CI/CD íŒŒì´í”„ë¼ì¸',
        language: 'python',
        framework: 'django',
        triggers: ['push', 'pull_request', 'release'],
        jenkinsIntegration: true,
        ecp_ai_integration: true
      },
      {
        id: 'react-spa',
        name: 'React SPA CI/CD',
        description: 'React ë‹¨ì¼ í˜ì´ì§€ ì• í”Œë¦¬ì¼€ì´ì…˜ìš© CI/CD',
        language: 'typescript',
        framework: 'react',
        triggers: ['push', 'pull_request'],
        jenkinsIntegration: false,
        ecp_ai_integration: true
      }
    ];
    
    res.json({
      success: true,
      data: templates,
      message: 'ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ì„ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.'
    });
    
  } catch (error) {
    console.error('âŒ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨:', error);
    res.status(500).json({
      success: false,
      message: 'ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      error: error.message
    });
  }
});

// [advice from AI] GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„± API (ë¬¸ì„œ ê°€ì´ë“œ ê¸°ë°˜)
router.post('/generate-workflow', verifyToken, async (req, res) => {
  try {
    console.log('ğŸ”„ GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹œì‘...');
    
    const { templateId, customConfig, repositoryAnalysis } = req.body;
    
    if (!customConfig || !customConfig.workflowName || !customConfig.language) {
      return res.status(400).json({
        success: false,
        message: 'ì›Œí¬í”Œë¡œìš° ì´ë¦„ê³¼ ì–¸ì–´ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.'
      });
    }

    // ì›Œí¬í”Œë¡œìš° ìƒì„±ê¸° í´ë˜ìŠ¤ ì‚¬ìš©
    const workflowGenerator = new GitHubActionsWorkflowGenerator();
    const generatedWorkflow = await workflowGenerator.generateWorkflow({
      templateId,
      customConfig,
      repositoryAnalysis
    });
    
    res.json({
      success: true,
      data: generatedWorkflow,
      message: 'GitHub Actions ì›Œí¬í”Œë¡œìš°ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
    });
    
  } catch (error) {
    console.error('âŒ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨:', error);
    res.status(500).json({
      success: false,
      message: 'ì›Œí¬í”Œë¡œìš° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      error: error.message
    });
  }
});

// [advice from AI] GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„±ê¸° í´ë˜ìŠ¤ (ë¬¸ì„œ ê°€ì´ë“œ ê¸°ë°˜)
class GitHubActionsWorkflowGenerator {
  constructor() {
    this.baseTemplates = {
      nodejs: this.getNodeJSTemplate(),
      python: this.getPythonTemplate(),
      java: this.getJavaTemplate(),
      go: this.getGoTemplate()
    };
  }

  async generateWorkflow({ templateId, customConfig, repositoryAnalysis }) {
    const { workflowName, language, enableJenkins, enableDocker, enableArgoCD } = customConfig;
    
    // ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ìƒì„±
    let workflow = this.getBaseWorkflow(language, customConfig);
    
    // Jenkins í•˜ì´ë¸Œë¦¬ë“œ í†µí•©
    if (enableJenkins) {
      workflow = this.addJenkinsIntegration(workflow, customConfig);
    }
    
    // Docker ì»¨í…Œì´ë„ˆí™”
    if (enableDocker) {
      workflow = this.addDockerSupport(workflow, customConfig);
    }
    
    // Argo CD GitOps
    if (enableArgoCD) {
      workflow = this.addArgoCDIntegration(workflow, customConfig);
    }
    
    // ì¶”ê°€ íŒŒì¼ë“¤ ìƒì„±
    const additionalFiles = {};
    
    if (enableJenkins) {
      additionalFiles.jenkinsfile = this.generateJenkinsfile(customConfig);
    }
    
    if (enableDocker) {
      additionalFiles.dockerfile = this.generateDockerfile(language, customConfig);
    }
    
    if (enableArgoCD) {
      additionalFiles.argocd_application = this.generateArgoCDApplication(customConfig);
      additionalFiles.helm_values = this.generateHelmValues(customConfig);
    }

    return {
      name: workflowName,
      yaml: workflow,
      ...additionalFiles
    };
  }

  getBaseWorkflow(language, config) {
    const { workflowName, triggers, nodeVersion, pythonVersion } = config;
    
    const triggerSection = this.generateTriggers(triggers);
    const jobsSection = this.generateJobs(language, config);
    
    return `name: ${workflowName}

${triggerSection}

jobs:
${jobsSection}`;
  }

  generateTriggers(triggers) {
    const triggerMap = {
      push: 'push:\n    branches: [ main, develop ]',
      pull_request: 'pull_request:\n    branches: [ main ]',
      release: 'release:\n    types: [ published ]',
      schedule: 'schedule:\n    - cron: "0 2 * * 1"',
      workflow_dispatch: 'workflow_dispatch:'
    };
    
    const activeTriggers = triggers.map(t => triggerMap[t]).filter(Boolean);
    
    return `on:
  ${activeTriggers.join('\n  ')}`;
  }

  generateJobs(language, config) {
    const { enableTesting, enableSecurity, enableCodeQuality, nodeVersion, pythonVersion } = config;
    
    let jobs = '';
    
    // ê¸°ë³¸ ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸ Job
    jobs += this.getBuildJob(language, config);
    
    // ë³´ì•ˆ ìŠ¤ìº” Job
    if (enableSecurity) {
      jobs += '\n\n' + this.getSecurityJob();
    }
    
    // ì½”ë“œ í’ˆì§ˆ Job
    if (enableCodeQuality) {
      jobs += '\n\n' + this.getCodeQualityJob(language);
    }
    
    // Docker ë¹Œë“œ Job
    if (config.enableDocker) {
      jobs += '\n\n' + this.getDockerJob();
    }
    
    return jobs;
  }

  getBuildJob(language, config) {
    const languageSetups = {
      javascript: this.getNodeSetup(config.nodeVersion),
      typescript: this.getNodeSetup(config.nodeVersion),
      python: this.getPythonSetup(config.pythonVersion),
      java: this.getJavaSetup(config.javaVersion),
      go: this.getGoSetup()
    };
    
    const setup = languageSetups[language] || languageSetups.javascript;
    
    return `  build:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
${setup}
      
    - name: Install dependencies
      run: ${this.getInstallCommand(language)}
      
    - name: Run tests
      run: ${this.getTestCommand(language)}
      
    - name: Build application
      run: ${this.getBuildCommand(language)}`;
  }

  getNodeSetup(version) {
    return `    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '${version}'
        cache: 'npm'`;
  }

  getPythonSetup(version) {
    return `    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '${version}'
        cache: 'pip'`;
  }

  getJavaSetup(version) {
    return `    - name: Setup Java
      uses: actions/setup-java@v4
      with:
        java-version: '${version}'
        distribution: 'temurin'
        cache: 'maven'`;
  }

  getGoSetup() {
    return `    - name: Setup Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
        cache: true`;
  }

  getInstallCommand(language) {
    const commands = {
      javascript: 'npm ci',
      typescript: 'npm ci',
      python: 'pip install -r requirements.txt',
      java: 'mvn clean compile',
      go: 'go mod download'
    };
    return commands[language] || 'npm ci';
  }

  getTestCommand(language) {
    const commands = {
      javascript: 'npm test',
      typescript: 'npm test',
      python: 'pytest',
      java: 'mvn test',
      go: 'go test ./...'
    };
    return commands[language] || 'npm test';
  }

  getBuildCommand(language) {
    const commands = {
      javascript: 'npm run build',
      typescript: 'npm run build',
      python: 'python setup.py build',
      java: 'mvn package',
      go: 'go build -o app .'
    };
    return commands[language] || 'npm run build';
  }

  getSecurityJob() {
    return `  security:
    runs-on: ubuntu-latest
    needs: build
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run security scan
      uses: github/super-linter@v5
      env:
        DEFAULT_BRANCH: main
        GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}`;
  }

  getCodeQualityJob(language) {
    return `  code-quality:
    runs-on: ubuntu-latest
    needs: build
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: SonarCloud Scan
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: \${{ secrets.SONAR_TOKEN }}`;
  }

  getDockerJob() {
    return `  docker:
    runs-on: ubuntu-latest
    needs: build
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: \${{ secrets.REGISTRY_URL }}
        username: \${{ secrets.REGISTRY_USERNAME }}
        password: \${{ secrets.REGISTRY_PASSWORD }}
        
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: \${{ secrets.REGISTRY_URL }}/\${{ github.repository }}:\${{ github.sha }}`;
  }

  addJenkinsIntegration(workflow, config) {
    // Jenkins íŠ¸ë¦¬ê±° Job ì¶”ê°€
    const jenkinsJob = `
  trigger-jenkins:
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Trigger Jenkins Pipeline
      run: |
        curl -X POST \\
          -H "Authorization: Bearer \${{ secrets.JENKINS_TOKEN }}" \\
          -H "Content-Type: application/json" \\
          -d '{"parameter": [{"name": "GITHUB_SHA", "value": "\${{ github.sha }}"}]}' \\
          "\${{ secrets.JENKINS_URL }}/job/\${{ github.repository }}/build"`;
    
    return workflow + jenkinsJob;
  }

  addDockerSupport(workflow, config) {
    // Docker ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ ë° ë‹¨ê³„ëŠ” ì´ë¯¸ getDockerJobì—ì„œ ì²˜ë¦¬ë¨
    return workflow;
  }

  addArgoCDIntegration(workflow, config) {
    const argoCDJob = `
  deploy:
    runs-on: ubuntu-latest
    needs: [docker]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout GitOps repo
      uses: actions/checkout@v4
      with:
        repository: \${{ secrets.GITOPS_REPO }}
        token: \${{ secrets.GITOPS_TOKEN }}
        path: gitops
        
    - name: Update image tag
      run: |
        cd gitops
        sed -i "s|image: .*|image: \${{ secrets.REGISTRY_URL }}/\${{ github.repository }}:\${{ github.sha }}|" \\
          applications/\${{ github.event.repository.name }}/values.yaml
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        git add .
        git commit -m "Update image tag to \${{ github.sha }}"
        git push`;
    
    return workflow + argoCDJob;
  }

  generateJenkinsfile(config) {
    return `pipeline {
    agent any
    
    environment {
        REGISTRY_URL = credentials('registry-url')
        REGISTRY_CREDENTIALS = credentials('registry-credentials')
    }
    
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        
        stage('Build') {
            steps {
                script {
                    sh '${this.getBuildCommand(config.language)}'
                }
            }
        }
        
        stage('Test') {
            steps {
                script {
                    sh '${this.getTestCommand(config.language)}'
                }
            }
        }
        
        stage('Docker Build') {
            steps {
                script {
                    def image = docker.build("\${REGISTRY_URL}/${config.workflowName}:\${BUILD_NUMBER}")
                    docker.withRegistry("https://\${REGISTRY_URL}", REGISTRY_CREDENTIALS) {
                        image.push()
                        image.push('latest')
                    }
                }
            }
        }
        
        stage('Deploy to ECP-AI') {
            steps {
                script {
                    // ECP-AI ë°°í¬ ë¡œì§
                    sh '''
                        curl -X POST \\
                          -H "Authorization: Bearer \${ECP_AI_TOKEN}" \\
                          -H "Content-Type: application/json" \\
                          -d "{\\"image\\": \\"\${REGISTRY_URL}/${config.workflowName}:\${BUILD_NUMBER}\\"}" \\
                          "\${ECP_AI_ENDPOINT}/deploy"
                    '''
                }
            }
        }
    }
    
    post {
        always {
            cleanWs()
        }
    }
}`;
  }

  generateDockerfile(language, config) {
    const dockerfiles = {
      javascript: `FROM node:${config.nodeVersion}-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["npm", "start"]`,
      
      python: `FROM python:${config.pythonVersion}-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "app.py"]`,
      
      java: `FROM openjdk:${config.javaVersion}-jre-slim
WORKDIR /app
COPY target/*.jar app.jar
EXPOSE 8080
CMD ["java", "-jar", "app.jar"]`
    };
    
    return dockerfiles[language] || dockerfiles.javascript;
  }

  generateArgoCDApplication(config) {
    return `apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ${config.workflowName}
  namespace: argocd
spec:
  project: default
  source:
    repoURL: \${GITOPS_REPO_URL}
    targetRevision: HEAD
    path: applications/${config.workflowName}
  destination:
    server: https://kubernetes.default.svc
    namespace: ${config.deploymentEnvironments[0] || 'default'}
  syncPolicy:
    automated:
      prune: true
      selfHeal: true`;
  }

  generateHelmValues(config) {
    return `# Helm values for ${config.workflowName}
replicaCount: 2

image:
  repository: \${REGISTRY_URL}/${config.workflowName}
  tag: latest
  pullPolicy: Always

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - host: ${config.workflowName}.example.com
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80`;
  }

  // ê¸°ë³¸ í…œí”Œë¦¿ë“¤ (ê°„ì†Œí™”ëœ ë²„ì „)
  getNodeJSTemplate() {
    return {
      language: 'javascript',
      defaultSteps: ['checkout', 'setup-node', 'install', 'test', 'build']
    };
  }

  getPythonTemplate() {
    return {
      language: 'python',
      defaultSteps: ['checkout', 'setup-python', 'install', 'test', 'build']
    };
  }

  getJavaTemplate() {
    return {
      language: 'java',
      defaultSteps: ['checkout', 'setup-java', 'compile', 'test', 'package']
    };
  }

  getGoTemplate() {
    return {
      language: 'go',
      defaultSteps: ['checkout', 'setup-go', 'download', 'test', 'build']
    };
  }
}

module.exports = router;
